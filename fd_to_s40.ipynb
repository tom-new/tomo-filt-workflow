{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2742ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "import pyvista as pv\n",
    "from pathlib import Path\n",
    "import gdrift\n",
    "import spherical_tools as st\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cmasher as cmr\n",
    "import cmcrameri.cm as cmc\n",
    "cm = 1/2.54\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": \"None\",\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.size\": \"8\",\n",
    "    \"text.latex.preamble\": r\"\"\"\n",
    "        \\usepackage[T1]{fontenc}\n",
    "        \\usepackage{amsmath}\n",
    "        \\usepackage{upgreek}\n",
    "        \\usepackage{siunitx}\n",
    "        \\sisetup{detect-all}\n",
    "        \"\"\"\n",
    "})\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c028125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURABLE PARAMETERS ---\n",
    "pvtu_file = Path(\n",
    "    \"/Volumes/Navy/firedrake_simulations/HT_4e8/Z22/0Ma/output_0.pvtu\"\n",
    ")  # Path to your .pvtu file\n",
    "depth_res = 50  # Distance between depth slices in km\n",
    "lon_res, lat_res = (\n",
    "    360 // 1 + 1,\n",
    "    180 // 1 + 1,\n",
    ")  # Grid resolution (number of points in lon/lat)\n",
    "cmb_depth = 2890  # CMB depth in km\n",
    "r_earth_km = 6370  # Radius of the Earth in km\n",
    "\n",
    "# path to models directory in S40RTS code\n",
    "name = \"HTZ22\"\n",
    "output_dir = Path(f\"/Volumes/Navy/firedrake_simulations/HT_4e8/Z22/S40RTS_ToFi/interpolated_layers\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4293166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOAD DATA ---\n",
    "def load_pvtu_points(pvtu_file):\n",
    "    model = pv.read(pvtu_file).clean()\n",
    "    model.points *= r_earth_km * 1.e3 / 2.208  # normalise the model\n",
    "    # drop unneeded arrays\n",
    "    for array_name in model.point_data.keys():\n",
    "        if array_name not in [\"FullTemperature_CG\", \"Temperature_Deviation_CG\"]:\n",
    "            del model.point_data[array_name]\n",
    "    # calculate T and T_av, dropping arrays after they become unneeded\n",
    "    model.point_data[\"T\"] = model[\"FullTemperature_CG\"] * 3700 + 300\n",
    "    model.point_data[\"dT\"] = model[\"Temperature_Deviation_CG\"] * (\n",
    "        np.max(model[\"T\"]) - np.min(model[\"T\"])\n",
    "    )\n",
    "    model.point_data[\"T_av\"] = model[\"T\"] - model[\"dT\"]\n",
    "    # depth in meters\n",
    "    model.point_data[\"depth\"] = r_earth_km * 1.e3 - np.linalg.norm(\n",
    "        model.points, axis=1\n",
    "    )\n",
    "\n",
    "    # initialise thermodynamic model\n",
    "    slb_pyrolite = gdrift.ThermodynamicModel(\n",
    "        \"SLB_16\",\n",
    "        \"pyrolite\",\n",
    "        temps=np.linspace(300, 4000),\n",
    "        depths=np.linspace(0, cmb_depth * 1.e3),\n",
    "    )\n",
    "\n",
    "    # A temperautre profile representing the mantle average temperature\n",
    "    # This is used to anchor the regularised thermodynamic table (we make sure the seismic speeds are the same at those temperature for the regularised and unregularised table)\n",
    "    temperature_spline = gdrift.SplineProfile(\n",
    "        depth=np.asarray([0., 500.e3, 2700.e3, 3000.e3]),\n",
    "        value=np.asarray([300., 1000., 3000., 4000.]),\n",
    "    )\n",
    "\n",
    "    # Regularising the table\n",
    "    # Regularisation works by saturating the minimum and maximum of variable gradients with respect to temperature.\n",
    "    # Default values are between -inf and 0.0; which essentialy prohibits phase jumps that would otherwise render\n",
    "    # v_s/v_p/rho versus temperature non-unique.\n",
    "    linear_slb_pyrolite = gdrift.mineralogy.regularise_thermodynamic_table(\n",
    "        slb_pyrolite,\n",
    "        temperature_spline,\n",
    "        regular_range={\"v_s\": [-0.5, 0.0], \"v_p\": [-0.5, 0.0], \"rho\": [-0.5, 0.0]},\n",
    "    )\n",
    "\n",
    "    cammarano_q_model = \"Q6\"  # choose model from cammarano et al., 2003\n",
    "    anelasticity = gdrift.CammaranoAnelasticityModel.from_q_profile(\n",
    "        cammarano_q_model\n",
    "    )  # Instantiate the anelasticity model\n",
    "    # apply anelastic correction\n",
    "    linear_anelastic_slb_pyrolite = gdrift.apply_anelastic_correction(\n",
    "        linear_slb_pyrolite, anelasticity\n",
    "    )\n",
    "\n",
    "    # compute seismic velocities in P and S\n",
    "    model.point_data[\"Vs\"] = linear_anelastic_slb_pyrolite.temperature_to_vs(\n",
    "        temperature=np.array(model[\"T\"]), depth=np.array(model[\"depth\"])\n",
    "    )\n",
    "    model.point_data[\"Vp\"] = linear_anelastic_slb_pyrolite.temperature_to_vp(\n",
    "        temperature=np.array(model[\"T\"]), depth=np.array(model[\"depth\"])\n",
    "    )\n",
    "\n",
    "    # compute layer average seismic velocities in P and S\n",
    "    model.point_data[\"Vs_av\"] = linear_slb_pyrolite.temperature_to_vs(\n",
    "        temperature=np.array(model[\"T_av\"]), depth=np.array(model[\"depth\"])\n",
    "    )\n",
    "    model.point_data[\"Vp_av\"] = linear_slb_pyrolite.temperature_to_vp(\n",
    "        temperature=np.array(model[\"T_av\"]), depth=np.array(model[\"depth\"])\n",
    "    )\n",
    "\n",
    "    # compute fractional perturbations in P and S\n",
    "    model.point_data[\"dVs\"] = 100 * (model[\"Vs\"] - model[\"Vs_av\"]) / model[\"Vs_av\"]\n",
    "    model.point_data[\"dVp\"] = 100 * (model[\"Vp\"] - model[\"Vp_av\"]) / model[\"Vp_av\"]\n",
    "\n",
    "    return model.points / 1.e3, model[\"dVs\"], model[\"dVp\"], model[\"depth\"] / 1.e3\n",
    "\n",
    "\n",
    "# --- SLICE GENERATION ---\n",
    "def get_depths_by_number(N):\n",
    "    depths = np.linspace(0, cmb_depth, N).tolist()\n",
    "    return depths\n",
    "\n",
    "\n",
    "def get_depths_by_resolution(depth_res):\n",
    "    # calculate number of depth slices starting from 0 such that the first N-1 slices are `depth_res` apart and the last slice is at the CMB depth\n",
    "    N_slices = int(np.ceil(cmb_depth / depth_res)) + 1\n",
    "    # calculate depth slice values\n",
    "    depths = [depth_res * i for i in range(N_slices - 1)] + [cmb_depth]\n",
    "    return depths\n",
    "\n",
    "\n",
    "# --- GRID GENERATION ---\n",
    "def get_lonlat_grid(lon_res, lat_res):\n",
    "    lons = np.linspace(-180, 180, lon_res)\n",
    "    lats = np.linspace(-90, 90, lat_res)\n",
    "    lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "    return lon_grid, lat_grid\n",
    "\n",
    "\n",
    "# --- INTERPOLATION ---\n",
    "def idw_interpolate(tree, values, query_points, k=1000, eps=1e-12):\n",
    "    dists, idxs = tree.query(query_points, k=k)\n",
    "    weights = 1.0 / (dists + eps)\n",
    "    weights /= weights.sum(axis=1, keepdims=True)\n",
    "    interpolated_values = []\n",
    "    for val in values:\n",
    "        interpolated_values.append(np.sum(val[idxs] * weights, axis=1))\n",
    "    return interpolated_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea4063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_points, dVs, dVp, fd_depths = load_pvtu_points(pvtu_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be75218",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get array of Firedrake layer average depths\n",
    "# reshape such that the first index is a layer of the mesh and the second index is the depths at each point in that layer\n",
    "firedrake_depths = fd_depths.reshape(-1,129).T\n",
    "# take the mean of the depths at each layer\n",
    "firedrake_depths = np.mean(firedrake_depths, axis=1)\n",
    "# flip the array to have the shallowest layer first\n",
    "firedrake_depths = np.flip(firedrake_depths)\n",
    "\n",
    "## Create points for interpolation\n",
    "# create array of interpolation depths\n",
    "interpolation_depths = get_depths_by_resolution(depth_res)\n",
    "# create arrays for lon and lat interpolation locations\n",
    "interpolation_lons, interpolation_lats = get_lonlat_grid(lon_res, lat_res)\n",
    "# convert to Cartesian coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d529138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing depth slice 0 to 50 km\n",
      "Max dVs: 1.67%; min dVs: -12.44%\n",
      "Processing depth slice 50 to 100 km\n",
      "Max dVs: 3.83%; min dVs: -15.16%\n",
      "Processing depth slice 100 to 150 km\n",
      "Max dVs: 4.20%; min dVs: -10.36%\n",
      "Processing depth slice 150 to 200 km\n",
      "Max dVs: 4.13%; min dVs: -7.53%\n",
      "Processing depth slice 200 to 250 km\n",
      "Max dVs: 3.93%; min dVs: -6.15%\n",
      "Processing depth slice 250 to 300 km\n",
      "Max dVs: 3.58%; min dVs: -4.61%\n",
      "Processing depth slice 300 to 350 km\n",
      "Max dVs: 2.51%; min dVs: -3.15%\n",
      "Processing depth slice 350 to 400 km\n",
      "Max dVs: 2.18%; min dVs: -2.83%\n",
      "Processing depth slice 400 to 450 km\n",
      "Max dVs: 2.01%; min dVs: -2.44%\n",
      "Processing depth slice 450 to 500 km\n",
      "Max dVs: 2.40%; min dVs: -2.87%\n",
      "Processing depth slice 500 to 550 km\n",
      "Max dVs: 1.92%; min dVs: -2.81%\n",
      "Processing depth slice 550 to 600 km\n",
      "Max dVs: 2.00%; min dVs: -3.33%\n",
      "Processing depth slice 600 to 650 km\n",
      "Max dVs: 1.48%; min dVs: -3.24%\n",
      "Processing depth slice 650 to 700 km\n",
      "Max dVs: 1.42%; min dVs: -3.14%\n",
      "Processing depth slice 700 to 750 km\n",
      "Max dVs: 1.62%; min dVs: -2.98%\n",
      "Processing depth slice 750 to 800 km\n",
      "Max dVs: 1.55%; min dVs: -2.50%\n",
      "Processing depth slice 800 to 850 km\n",
      "Max dVs: 1.47%; min dVs: -2.44%\n",
      "Processing depth slice 850 to 900 km\n",
      "Max dVs: 1.18%; min dVs: -2.25%\n",
      "Processing depth slice 900 to 950 km\n",
      "Max dVs: 1.08%; min dVs: -2.38%\n",
      "Processing depth slice 950 to 1000 km\n",
      "Max dVs: 1.15%; min dVs: -2.54%\n",
      "Processing depth slice 1000 to 1050 km\n",
      "Max dVs: 1.21%; min dVs: -2.76%\n",
      "Processing depth slice 1050 to 1100 km\n",
      "Max dVs: 1.29%; min dVs: -2.94%\n",
      "Processing depth slice 1100 to 1150 km\n",
      "Max dVs: 0.88%; min dVs: -2.44%\n",
      "Processing depth slice 1150 to 1200 km\n",
      "Max dVs: 0.93%; min dVs: -3.08%\n",
      "Processing depth slice 1200 to 1250 km\n",
      "Max dVs: 0.45%; min dVs: -2.46%\n",
      "Processing depth slice 1250 to 1300 km\n",
      "Max dVs: 0.45%; min dVs: -2.44%\n",
      "Processing depth slice 1300 to 1350 km\n",
      "Max dVs: 0.70%; min dVs: -2.84%\n",
      "Processing depth slice 1350 to 1400 km\n",
      "Max dVs: 0.32%; min dVs: -2.20%\n",
      "Processing depth slice 1400 to 1450 km\n",
      "Max dVs: 0.35%; min dVs: -2.16%\n",
      "Processing depth slice 1450 to 1500 km\n",
      "Max dVs: 0.31%; min dVs: -2.12%\n",
      "Processing depth slice 1500 to 1550 km\n",
      "Max dVs: 0.48%; min dVs: -2.48%\n",
      "Processing depth slice 1550 to 1600 km\n",
      "Max dVs: 0.29%; min dVs: -1.91%\n",
      "Processing depth slice 1600 to 1650 km\n",
      "Max dVs: 0.39%; min dVs: -1.90%\n",
      "Processing depth slice 1650 to 1700 km\n",
      "Max dVs: 0.47%; min dVs: -1.94%\n",
      "Processing depth slice 1700 to 1750 km\n",
      "Max dVs: 0.46%; min dVs: -1.98%\n",
      "Processing depth slice 1750 to 1800 km\n",
      "Max dVs: 0.54%; min dVs: -2.01%\n",
      "Processing depth slice 1800 to 1850 km\n",
      "Max dVs: 0.61%; min dVs: -2.04%\n",
      "Processing depth slice 1850 to 1900 km\n",
      "Max dVs: 0.65%; min dVs: -2.06%\n",
      "Processing depth slice 1900 to 1950 km\n",
      "Max dVs: 0.64%; min dVs: -2.11%\n",
      "Processing depth slice 1950 to 2000 km\n",
      "Max dVs: 0.62%; min dVs: -2.18%\n",
      "Processing depth slice 2000 to 2050 km\n",
      "Max dVs: 0.61%; min dVs: -2.24%\n",
      "Processing depth slice 2050 to 2100 km\n",
      "Max dVs: 0.62%; min dVs: -2.29%\n",
      "Processing depth slice 2100 to 2150 km\n",
      "Max dVs: 0.64%; min dVs: -2.33%\n",
      "Processing depth slice 2150 to 2200 km\n",
      "Max dVs: 0.78%; min dVs: -2.35%\n",
      "Processing depth slice 2200 to 2250 km\n",
      "Max dVs: 0.86%; min dVs: -2.34%\n",
      "Processing depth slice 2250 to 2300 km\n",
      "Max dVs: 0.83%; min dVs: -2.31%\n",
      "Processing depth slice 2300 to 2350 km\n",
      "Max dVs: 0.70%; min dVs: -2.30%\n",
      "Processing depth slice 2350 to 2400 km\n",
      "Max dVs: 0.71%; min dVs: -2.30%\n",
      "Processing depth slice 2400 to 2450 km\n",
      "Max dVs: 0.70%; min dVs: -2.36%\n",
      "Processing depth slice 2450 to 2500 km\n",
      "Max dVs: 0.66%; min dVs: -2.42%\n",
      "Processing depth slice 2500 to 2550 km\n",
      "Max dVs: 0.61%; min dVs: -2.48%\n",
      "Processing depth slice 2550 to 2600 km\n",
      "Max dVs: 0.83%; min dVs: -3.01%\n",
      "Processing depth slice 2600 to 2650 km\n",
      "Max dVs: 0.63%; min dVs: -2.92%\n",
      "Processing depth slice 2650 to 2700 km\n",
      "Max dVs: 0.65%; min dVs: -3.78%\n",
      "Processing depth slice 2700 to 2750 km\n",
      "Max dVs: 0.53%; min dVs: -4.17%\n",
      "Processing depth slice 2750 to 2800 km\n",
      "Max dVs: 0.51%; min dVs: -4.12%\n",
      "Processing depth slice 2800 to 2850 km\n",
      "Max dVs: 0.35%; min dVs: -3.26%\n",
      "Processing depth slice 2850 to 2890 km\n",
      "Max dVs: -0.57%; min dVs: -2.09%\n"
     ]
    }
   ],
   "source": [
    "# create array to hold interpolated values\n",
    "interpolated_dVs = np.empty((len(interpolation_depths) - 1, interpolation_lons.size))\n",
    "interpolated_dVp = np.empty((len(interpolation_depths) - 1, interpolation_lons.size))\n",
    "\n",
    "for i in range(len(interpolation_depths) - 1):\n",
    "    print(f\"Processing depth slice {interpolation_depths[i]} to {interpolation_depths[i + 1]} km\")\n",
    "    ## Select points between depth boundaries (slices will be at the midpoint between depths)\n",
    "    ## Create mask for depth slice\n",
    "    # we need to ensure that we have at least 1 Firedrake layer between depths[i-1] and depths[i], and if not, widen it gradually\n",
    "    top = interpolation_depths[i]\n",
    "    bottom = interpolation_depths[i + 1]\n",
    "    step = (bottom - top) / 4 # amount by which to expand the depth slice above and below the slice\n",
    "    found = False\n",
    "    mask = np.empty_like(fd_depths, dtype=bool)\n",
    "    while not found:\n",
    "        idx_top = np.searchsorted(firedrake_depths, top, side='right')\n",
    "        idx_bottom = np.searchsorted(firedrake_depths, bottom, side='left')\n",
    "        if idx_top < idx_bottom:\n",
    "            # we have at least one Firedrake layer in the slice\n",
    "            found = True\n",
    "            # create mask\n",
    "            mask = (fd_depths >= top) & (fd_depths < bottom)\n",
    "        else:\n",
    "            # we need to widen the depth slice\n",
    "            print(f\"No Firedrake layers found in [{top},{bottom}] km, expanding slice...\")\n",
    "            top -= step\n",
    "            bottom += step\n",
    "            print(f\"...expanded depth slice to [{top},{bottom}] km\")\n",
    "\n",
    "    slice_points = fd_points[mask]\n",
    "    slice_dVs = dVs[mask]\n",
    "    slice_dVp = dVp[mask]\n",
    "    ## Build KDTree and interpolate\n",
    "    tree = KDTree(slice_points)\n",
    "    # convert grid points to Cartesian coordinates\n",
    "    query_points = np.column_stack(\n",
    "        [\n",
    "            (r_earth_km - interpolation_depths[i]) * np.ones(interpolation_lons.size),\n",
    "            interpolation_lons.reshape(-1),\n",
    "            interpolation_lats.reshape(-1),\n",
    "        ]\n",
    "    )\n",
    "    query_points = st.geo2cart(query_points, degrees=True)\n",
    "\n",
    "    # interpolate using IDW and add to carrying arrays\n",
    "    interpolated_dVs[i], interpolated_dVp[i] = idw_interpolate(\n",
    "        tree, [slice_dVs, slice_dVp], query_points\n",
    "    )\n",
    "    # print(f\"Max dVs: {interpolated_dVs[i].max():.2f}%; min dVs: {interpolated_dVs[i].min():.2f}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed3e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save depths\n",
    "np.savetxt(output_dir / \"depth_layers.dat\", interpolation_depths, fmt='%04d', newline='\\n')\n",
    "\n",
    "# save interpolated dVs values\n",
    "interpolation_lons_to_save = interpolation_lons.reshape(-1)\n",
    "interpolation_lats_to_save = interpolation_lats.reshape(-1)\n",
    "\n",
    "lon_b, lat_b, dVs_b, dVp_b = np.broadcast_arrays(\n",
    "    interpolation_lons_to_save[np.newaxis, :],\n",
    "    interpolation_lats_to_save[np.newaxis, :],\n",
    "    interpolated_dVs,\n",
    "    interpolated_dVp,\n",
    ")\n",
    "\n",
    "dVs_to_save = np.stack([lon_b, lat_b, dVs_b], axis=-1)\n",
    "dVp_to_save = np.stack([lon_b, lat_b, dVp_b], axis=-1)\n",
    "\n",
    "for i in range(len(interpolation_depths) - 1):\n",
    "    output_file_dVs = output_dir / f\"{name}.dvs.layer.{i+1:03d}.dat\"\n",
    "    # output_file_dVp = output_dir / f\"{name}.dvp.layer.{i+1:03d}.dat\"\n",
    "    np.savetxt(output_file_dVs, dVs_to_save[i], fmt=['%.2f', '%.2f', '%.8f'], delimiter=' ', newline='\\n')\n",
    "    # np.savetxt(output_file_dVp, dVp_to_save[i], fmt=['%.2f', '%.2f', '%.8f'], delimiter=' ', newline='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
